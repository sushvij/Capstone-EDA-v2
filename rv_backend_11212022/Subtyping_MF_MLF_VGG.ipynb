{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZJpClcxjJmS"
      },
      "source": [
        "## Subtyping Mitotic Figures (MF) and Mitotic-Like Figures (MLFs) "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I. Imports"
      ],
      "metadata": {
        "id": "5oSeifJCWyt1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLFU6UQSQDgp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import optimizers\n",
        "import numpy as np\n",
        "from numpy.core.multiarray import packbits\n",
        "import pandas as pd\n",
        "import os\n",
        "from os import listdir\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from matplotlib import image as mpimg\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xr9D7ZdtXbjo",
        "outputId": "9379d7f8-2bb9-4397-ef94-78b11bbae3f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "#This cell is only relevant if using Google Colab and Google Drive.  It should not be run unless running this Jupyter Notebook in Google Colab.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrG0M0bSXsi6",
        "outputId": "2981d487-a878-4f34-b13c-930a1605e743"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "#This cell is only relevant if using Google Colab and Google Drive.  It should not be run unless running this Jupyter Notebook in Google Colab.\n",
        "%cd drive/MyDrive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oi5WYmASjlU4"
      },
      "source": [
        "II. Data Upload and Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnQkrO2MXup_"
      },
      "outputs": [],
      "source": [
        "#Here, we read in FSL annotations and concatenate them into a single Pandas dataframe.\n",
        "data1 = pd.read_csv('fsl_subclassing/slide_2_updated/20221116-115200_ann_df_re-subcl_slide_no_2_all_64_MFs.csv')\n",
        "data2 = pd.read_csv('fsl_subclassing/slide_2/20221030-011825_annot_df_sorted_subclassed_MLFs_32_slide_no_2.csv')\n",
        "data3 =  pd.read_csv('fsl_subclassing/slide_3/20221112-015900_annot_df_sorted_subclassed_MLFs_72_slide_no_3.csv')\n",
        "data4 =  pd.read_csv('fsl_subclassing/slide_3/20221112-003547_annot_df_sorted_subclassed_slide_no_3_all_MFs.csv')\n",
        "data5 = pd.read_csv('fsl_subclassing/slide_5/20221112-230321_annot_df_sorted_subclassed_MLFs_100_slide_no_5.csv')\n",
        "data6 = pd.read_csv('fsl_subclassing/slide_5/221211-35722_ann_df_subcl_CORRECTED_sl_5_all_130_MFs.csv')\n",
        "data7 = pd.read_csv('fsl_subclassing/slide_7/20221115-150013_annot_df_sorted_subclassed_MLFs_160_slide_no_7.csv')\n",
        "data8 = pd.read_csv('fsl_subclassing/slide_7/20221115-150013_ann_df_subcl_slide_no_7_all_157_MFs.csv')\n",
        "data9 = pd.read_csv('fsl_subclassing/slide_8/20221116-092800_ann_df_subcl_slide_no_8_all_187_MFs.csv')\n",
        "data10 = pd.read_csv('fsl_subclassing/slide_8/20221116-092800_annot_df_sorted_subclassed_MLFs_100_slide_no_8.csv')\n",
        "data = pd.concat([data1, data2, data3, data4, data5, data6, data7, data8, data9,data10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3sHnetZJ-ae",
        "outputId": "fbd137d0-fbb2-4b00-9d6f-0f9fd6d2e8eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/MITOS_WSI_CMC/databases\n"
          ]
        }
      ],
      "source": [
        "#This cell is only relevant if using Google Colab and Google Drive.  It should not be run unless running this Jupyter Notebook in Google Colab.\n",
        "%cd MITOS_WSI_CMC/databases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxryeOpaYHFB"
      },
      "outputs": [],
      "source": [
        "#The FSL annotations have labels 9 and 42, which are equivalent, and 0, none of which should be used for training.  We drop these.\n",
        "data.head()\n",
        "data['subcl'] = data['subcl'].replace(42,9)\n",
        "data_filtered = data[data['subcl'] != 9]\n",
        "data = data_filtered.copy()\n",
        "data = data[data['subcl'] != 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yESnHiqlYKB_",
        "outputId": "454e267b-3a7c-43ea-e5b0-3651418f860f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "984"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#The FSL subclass annotations extracted from the dataframe to train on.\n",
        "subclass_annotations = data.drop(['ctr', 'coord', 'guid'], axis = 1)\n",
        "subclass_annotations.head()\n",
        "len(subclass_annotations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTfmnyObQJCC"
      },
      "outputs": [],
      "source": [
        "#Here, we load the images from the files we wrote during the patch extraction step.\n",
        "\n",
        "\n",
        "labels = subclass_annotations['subcl']\n",
        "imagelist = []\n",
        "\n",
        "# get the path/directory\n",
        "folder_dir = \"databases\"\n",
        "i = 0\n",
        "\n",
        "#We use a loop to read in images from each slide and name them with a filename convention that includes the slide in the ID.\n",
        "while (i<93):\n",
        "        temp = mpimg.imread('/content/drive/MyDrive/MITOS_WSI_CMC/databases/patchExtraction_final/' + str(2) + str(i) + str('.png'))\n",
        "        imagelist.append(temp)\n",
        "        i = i + 1\n",
        "i = 0\n",
        "while (i<155):\n",
        "        temp = mpimg.imread('/content/drive/MyDrive/MITOS_WSI_CMC/databases/patchExtraction_final/' + str(3) + str(i) + str('.png'))\n",
        "        imagelist.append(temp)\n",
        "        i = i + 1\n",
        "i = 0\n",
        "while (i<203):\n",
        "        temp = mpimg.imread('/content/drive/MyDrive/MITOS_WSI_CMC/databases/patchExtraction_final/' + str(5) + str(i) + str('.png'))\n",
        "        imagelist.append(temp)\n",
        "        i = i + 1\n",
        "i = 0\n",
        "while (i<303):\n",
        "        temp = mpimg.imread('/content/drive/MyDrive/MITOS_WSI_CMC/databases/patchExtraction_final/' + str(7) + str(i) + str('.png'))\n",
        "        imagelist.append(temp)\n",
        "        i = i + 1\n",
        "i = 0\n",
        "while (i<230):\n",
        "        temp = mpimg.imread('/content/drive/MyDrive/MITOS_WSI_CMC/databases/patchExtraction_final/' + str(8) + str(i) + str('.png'))\n",
        "        imagelist.append(temp)\n",
        "        i = i + 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OA1egc2gDHrm"
      },
      "outputs": [],
      "source": [
        "#Here, we collapse labels 3,4, and 5 into just label 5.  \n",
        "labels = np.asarray(labels)\n",
        "i = 0\n",
        "while i<len(labels):\n",
        "    if (np.equal(int(labels[i]),3)):\n",
        "       labels[i] = 5\n",
        "    elif (np.equal(int(labels[i]),4)):\n",
        "       labels[i] = 5\n",
        "    i = i + 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhxYTm3DFLS2"
      },
      "outputs": [],
      "source": [
        "#Labels are manually one-hot encoded.\n",
        "i = 0\n",
        "ohe_labels = [0] * len(labels)\n",
        "while (i<len(labels)):\n",
        "      if (labels[i] == 5):\n",
        "         ohe_labels[i] = [0, 0, 0, 1]\n",
        "      elif (labels[i] == 6):\n",
        "         ohe_labels[i] = [0, 0, 1, 0]\n",
        "      elif (labels[i] == 7):\n",
        "         ohe_labels[i] = [0, 1, 0, 0]\n",
        "      elif (labels[i] == 8):\n",
        "         ohe_labels[i] = [1, 0, 0, 0]\n",
        "      i = i + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oivKJPmdGLXq"
      },
      "outputs": [],
      "source": [
        "#Labels and images are put into \"X\" and \"y\" for the train-test split step.\n",
        "X = imagelist.copy()\n",
        "X = np.asarray(X)\n",
        "y = np.asarray(ohe_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfeBgLKMkzqK"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zR6rM-Zla6G"
      },
      "source": [
        "III. VGG16 for Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yXRd_cxE9iG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0612dcfb-df3b-4085-ea65-067c6c3e84ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "#VGG16 is initialized.\n",
        "\n",
        "vgg_model = tf.keras.applications.VGG16(include_top=False,weights=\"imagenet\",input_shape=(64,64,3),classifier_activation=\"relu\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKTRDml2X6Ho"
      },
      "outputs": [],
      "source": [
        "#The sizes of the dense layers were chosen as multiples of the number of classes.\n",
        "model = models.Sequential()\n",
        "model.add(vgg_model)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(4, activation='softmax'))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=optimizers.SGD(learning_rate=0.0001,momentum=0.0,nesterov=False,name='SGD'), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, batch_size=32, epochs=40, verbose=1, validation_data=(X_test , y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHq0bEsiQDyD",
        "outputId": "f6321a53-7bb2-44f1-cd5b-d752650faf59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "22/22 [==============================] - 142s 6s/step - loss: 1.4188 - accuracy: 0.3765 - val_loss: 1.3548 - val_accuracy: 0.4459\n",
            "Epoch 2/40\n",
            "22/22 [==============================] - 136s 6s/step - loss: 1.2731 - accuracy: 0.4622 - val_loss: 1.2931 - val_accuracy: 0.4628\n",
            "Epoch 3/40\n",
            "22/22 [==============================] - 140s 6s/step - loss: 1.2342 - accuracy: 0.4680 - val_loss: 1.2701 - val_accuracy: 0.4628\n",
            "Epoch 4/40\n",
            "22/22 [==============================] - 138s 6s/step - loss: 1.2149 - accuracy: 0.4753 - val_loss: 1.2574 - val_accuracy: 0.4595\n",
            "Epoch 5/40\n",
            "22/22 [==============================] - 137s 6s/step - loss: 1.2026 - accuracy: 0.4738 - val_loss: 1.2511 - val_accuracy: 0.4662\n",
            "Epoch 6/40\n",
            "22/22 [==============================] - 136s 6s/step - loss: 1.1919 - accuracy: 0.4782 - val_loss: 1.2460 - val_accuracy: 0.4696\n",
            "Epoch 7/40\n",
            "22/22 [==============================] - 141s 6s/step - loss: 1.1808 - accuracy: 0.4797 - val_loss: 1.2414 - val_accuracy: 0.4730\n",
            "Epoch 8/40\n",
            "22/22 [==============================] - 139s 6s/step - loss: 1.1710 - accuracy: 0.4855 - val_loss: 1.2368 - val_accuracy: 0.4764\n",
            "Epoch 9/40\n",
            "22/22 [==============================] - 139s 6s/step - loss: 1.1612 - accuracy: 0.4884 - val_loss: 1.2327 - val_accuracy: 0.4662\n",
            "Epoch 10/40\n",
            "22/22 [==============================] - 139s 6s/step - loss: 1.1528 - accuracy: 0.4898 - val_loss: 1.2281 - val_accuracy: 0.4662\n",
            "Epoch 11/40\n",
            "22/22 [==============================] - 139s 6s/step - loss: 1.1425 - accuracy: 0.4898 - val_loss: 1.2260 - val_accuracy: 0.4730\n",
            "Epoch 12/40\n",
            "22/22 [==============================] - 138s 6s/step - loss: 1.1328 - accuracy: 0.5058 - val_loss: 1.2225 - val_accuracy: 0.4662\n",
            "Epoch 13/40\n",
            "22/22 [==============================] - 140s 6s/step - loss: 1.1237 - accuracy: 0.5073 - val_loss: 1.2206 - val_accuracy: 0.4764\n",
            "Epoch 14/40\n",
            "22/22 [==============================] - 136s 6s/step - loss: 1.1149 - accuracy: 0.5116 - val_loss: 1.2156 - val_accuracy: 0.4831\n",
            "Epoch 15/40\n",
            "22/22 [==============================] - 138s 6s/step - loss: 1.1033 - accuracy: 0.5189 - val_loss: 1.2124 - val_accuracy: 0.4865\n",
            "Epoch 16/40\n",
            "22/22 [==============================] - 138s 6s/step - loss: 1.0972 - accuracy: 0.5233 - val_loss: 1.2087 - val_accuracy: 0.4764\n",
            "Epoch 17/40\n",
            "22/22 [==============================] - 137s 6s/step - loss: 1.0848 - accuracy: 0.5247 - val_loss: 1.2054 - val_accuracy: 0.4561\n",
            "Epoch 18/40\n",
            "22/22 [==============================] - 138s 6s/step - loss: 1.0768 - accuracy: 0.5436 - val_loss: 1.2017 - val_accuracy: 0.4561\n",
            "Epoch 19/40\n",
            "22/22 [==============================] - 138s 6s/step - loss: 1.0676 - accuracy: 0.5320 - val_loss: 1.2020 - val_accuracy: 0.4392\n",
            "Epoch 20/40\n",
            "22/22 [==============================] - 140s 6s/step - loss: 1.0579 - accuracy: 0.5596 - val_loss: 1.1993 - val_accuracy: 0.4696\n",
            "Epoch 21/40\n",
            "22/22 [==============================] - 137s 6s/step - loss: 1.0492 - accuracy: 0.5509 - val_loss: 1.1945 - val_accuracy: 0.4628\n",
            "Epoch 22/40\n",
            "22/22 [==============================] - 139s 6s/step - loss: 1.0400 - accuracy: 0.5669 - val_loss: 1.1948 - val_accuracy: 0.4662\n",
            "Epoch 23/40\n",
            "22/22 [==============================] - 139s 6s/step - loss: 1.0299 - accuracy: 0.5669 - val_loss: 1.1902 - val_accuracy: 0.4561\n",
            "Epoch 24/40\n",
            "22/22 [==============================] - 142s 6s/step - loss: 1.0218 - accuracy: 0.5770 - val_loss: 1.1899 - val_accuracy: 0.4628\n",
            "Epoch 25/40\n",
            "22/22 [==============================] - 140s 6s/step - loss: 1.0118 - accuracy: 0.5785 - val_loss: 1.1875 - val_accuracy: 0.4628\n",
            "Epoch 26/40\n",
            "22/22 [==============================] - 142s 6s/step - loss: 1.0029 - accuracy: 0.5945 - val_loss: 1.1854 - val_accuracy: 0.4595\n",
            "Epoch 27/40\n",
            "22/22 [==============================] - 141s 6s/step - loss: 0.9921 - accuracy: 0.5974 - val_loss: 1.1825 - val_accuracy: 0.4561\n",
            "Epoch 28/40\n",
            "22/22 [==============================] - 141s 6s/step - loss: 0.9806 - accuracy: 0.6017 - val_loss: 1.1834 - val_accuracy: 0.4696\n",
            "Epoch 29/40\n",
            "22/22 [==============================] - 138s 6s/step - loss: 0.9741 - accuracy: 0.6105 - val_loss: 1.1811 - val_accuracy: 0.4595\n",
            "Epoch 30/40\n",
            "22/22 [==============================] - 139s 6s/step - loss: 0.9648 - accuracy: 0.6105 - val_loss: 1.1805 - val_accuracy: 0.4831\n",
            "Epoch 31/40\n",
            "22/22 [==============================] - 139s 6s/step - loss: 0.9529 - accuracy: 0.6148 - val_loss: 1.1823 - val_accuracy: 0.4730\n",
            "Epoch 32/40\n",
            "22/22 [==============================] - 136s 6s/step - loss: 0.9459 - accuracy: 0.6221 - val_loss: 1.1746 - val_accuracy: 0.4595\n",
            "Epoch 33/40\n",
            "22/22 [==============================] - 137s 6s/step - loss: 0.9344 - accuracy: 0.6323 - val_loss: 1.1739 - val_accuracy: 0.4662\n",
            "Epoch 34/40\n",
            "22/22 [==============================] - 138s 6s/step - loss: 0.9266 - accuracy: 0.6337 - val_loss: 1.1708 - val_accuracy: 0.4696\n",
            "Epoch 35/40\n",
            "22/22 [==============================] - 139s 6s/step - loss: 0.9165 - accuracy: 0.6468 - val_loss: 1.1721 - val_accuracy: 0.4696\n",
            "Epoch 36/40\n",
            "22/22 [==============================] - 137s 6s/step - loss: 0.9065 - accuracy: 0.6497 - val_loss: 1.1691 - val_accuracy: 0.4764\n",
            "Epoch 37/40\n",
            "22/22 [==============================] - 138s 6s/step - loss: 0.8975 - accuracy: 0.6526 - val_loss: 1.1653 - val_accuracy: 0.4831\n",
            "Epoch 38/40\n",
            "22/22 [==============================] - 137s 6s/step - loss: 0.8869 - accuracy: 0.6526 - val_loss: 1.1672 - val_accuracy: 0.4966\n",
            "Epoch 39/40\n",
            "22/22 [==============================] - 138s 6s/step - loss: 0.8814 - accuracy: 0.6555 - val_loss: 1.1646 - val_accuracy: 0.4932\n",
            "Epoch 40/40\n",
            "22/22 [==============================] - 136s 6s/step - loss: 0.8691 - accuracy: 0.6730 - val_loss: 1.1703 - val_accuracy: 0.4865\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "V. Saving the Model Weights in .h5 format"
      ],
      "metadata": {
        "id": "3lHsPOyzW8xd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('final_model.h5')"
      ],
      "metadata": {
        "id": "is4c64s8YX1X"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}